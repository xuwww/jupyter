{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0U-Y1wbPbygR"
      },
      "source": [
        "# Project 1. Denoising Network\n",
        "\n",
        "In this project, you're going to implement a neural network to denoise images, there are several parts you need to implement to make the whole pipeline complete.\n",
        "\n",
        "1. Dataset\n",
        "2. Metrics\n",
        "3. Networks\n",
        "4. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av7yoW4YcR5B"
      },
      "source": [
        "## 1. Dataset\n",
        "\n",
        "In this project we are going to use an image dataset of 400 grayscale 180*180 images as our dataset, use command below to download the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwidPhfkc39A",
        "outputId": "652ee228-68fe-43f9-cdde-f795c51c4fcb"
      },
      "outputs": [],
      "source": [
        "!wget https://www.dropbox.com/s/dn6jv1qw5bpdcs9/ImageSet.zip?dl=0 -O ImageSet.zip\n",
        "!unzip -q ImageSet.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jW4hRCF6eeHN"
      },
      "source": [
        "Now you should have a folder called ImageSet, and there're 400 images in it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LM1Us1D8c7KW",
        "outputId": "dd880084-98e8-4bbe-f53b-8b3ef1c7e19e"
      },
      "outputs": [],
      "source": [
        "!ls ImageSet | wc -l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja3fqlMeewGz"
      },
      "source": [
        "Now you need to implement two classes, TrainingSet and TestingSet, you should first split your dataset into 350 images and 50 images. TrainingSet should use the 350 images to form a dataset, with each entry being a pair of image tensors, and the first image should be a noisy version of the second original image. In other words, `training_set[i]` should return `[noisy_image(=original_image + noise), original_image]`, and images should be tensors of shape $C\\times H\\times W$, in this case, $1\\times 180\\times 180$\n",
        "\n",
        "TestingSet is the same thing with the remaining 50 images.\n",
        "1. Please refer to the following code to add noise\n",
        "```python\n",
        "def add_noise(img):\n",
        "    noise = torch.randn(img.size()).mul_(self.sigma/255.0)\n",
        "    noisy = img + noise\n",
        "    noisy[torch.where(noisy > 1)] = 1\n",
        "    noisy[torch.where(noisy < 0)] = 0\n",
        "    return noisy\n",
        "```\n",
        "2. Also refer to the following code as how to read images from file to memory\n",
        "```python\n",
        "class RawImageSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, root):\n",
        "        self.root = root\n",
        "        self.all_image_files = os.listdir(root)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image_path = os.path.join(self.root, self.all_image_files[index])\n",
        "        img = PIL.Image.open(image_path)\n",
        "        return transforms.ToTensor()(img)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.all_image_files)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "C-YtQil-dXja"
      },
      "outputs": [],
      "source": [
        "# implement your TrainingSet and TestingSet here\n",
        "class TrainingSet:\n",
        "    pass\n",
        "\n",
        "class TestingSet:\n",
        "    pass\n",
        "\n",
        "# from data import TrainingSet, TestingSet # use this command to use our provided implementation as a placeholder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FdlQyoTjwy5"
      },
      "source": [
        "You can use the following code block to check if your implementation is correct, first, there should be **no error**, second, the shape of image should be **`[1, 180, 180]`**, and finally, in the drawing area, the **left hand side image should be noisier than the right hand side image**, but they should be images of the same thing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "DiGOuRLzhKo6",
        "outputId": "5e47a91d-9043-4aad-a4dd-72094778f881"
      },
      "outputs": [],
      "source": [
        "training_set = TrainingSet()\n",
        "testing_set = TestingSet()\n",
        "assert len(training_set) == 350\n",
        "assert len(testing_set) == 50\n",
        "\n",
        "print(f'Shape of image: {training_set[0][0].shape}')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "fig, axes = plt.subplots(1,2)\n",
        "axes[0].imshow(training_set[0][0][0], cmap='gray')\n",
        "axes[0].axis('off')\n",
        "axes[0].set_title('noisy example')\n",
        "axes[1].imshow(training_set[0][1][0], cmap='gray')\n",
        "axes[1].axis('off')\n",
        "axes[1].set_title('original example')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FupWN7QNkjhg"
      },
      "source": [
        "## 2. Metrics\n",
        "To quantify how noisy an image is compared to the original one, we're going to use PSNR, please implement a function `psnr` to return the psnr score.\n",
        "\n",
        "Refer to https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio about the formula of PSNR\n",
        "\n",
        "Note:\n",
        "1. higher PSNR means noise is relatively smaller, the PSNR of the original image is positive infinity, because the noise is zero.\n",
        "2. the psnr is a symetric function, meaning the psnr of a noisy image with respect to the original one is the same as the psnr of the original image with respect to the noisy one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ug9bsTAko9xy"
      },
      "outputs": [],
      "source": [
        "# implement your psnr function\n",
        "def psnr(original, noisy):\n",
        "    pass\n",
        "\n",
        "# from metrics import psnr # to skip this part"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLPEgcy8p3z-"
      },
      "source": [
        "Run the following code to check if the implementation is correct, the expected output should be about 7.96"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HG4T_HAMiMN_",
        "outputId": "d27072c3-11b0-4d5a-d185-a28592c16589"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "test_original = torch.tensor([[0.1, 0.2], [0.3, 0.4]])\n",
        "test_noisy = torch.tensor([[0.5, 0.6], [0.7, 0.8]])\n",
        "print(f'PSNR score: {psnr(test_original, test_noisy)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSLrNDK695Za"
      },
      "source": [
        "And we can calculate the psnr score for the noisy image pair we showed above, the score should be aroud 28, but there could be exception."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y8yQ5rV9_8T",
        "outputId": "8130af4c-ed2d-44b8-e240-0fa3b3da7cd8"
      },
      "outputs": [],
      "source": [
        "print(f'PSNR score for example images: {psnr(training_set[0][1], training_set[0][0])}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlNWtKbSrW7d"
      },
      "source": [
        "## 3. Network\n",
        "Now that we got dataset ready and metrics ready, we start preparing the network. You need to define a class `DenoiseNetwork` as your network class.\n",
        "\n",
        "The goal of your network is to take the noisy image as input and output the predicted **noise**. First of all, the input and the output of the network should have the same size, the main idea is to predict the original image first by going through several CNN layers, and then use the input noisy image to deduct predicted original image to get the noise, the pseudo code should be like:\n",
        "```python\n",
        "class DenoiseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        define some cnn layers and other necessary components\n",
        "    \n",
        "    def forward(self, x):\n",
        "        predicted_original_image = cnn_network(x)\n",
        "        noise = x - predicted_original_image\n",
        "        return noise\n",
        "```\n",
        "Then calculate the mean squared error between the predicted noise and the truth noise as our loss, and try to minimize it.\n",
        "\n",
        "Tips:\n",
        "1. you can use nn.MSELoss as your loss function\n",
        "2. Use Adam instead of SGD as your optimizer, initial learning rate set to 0.001\n",
        "3. Use `torch.nn.init.orthogonal_` to initialize the `weight` of your cnn layers as orthogonal matrices, and use `torch.nn.init.constant_` to fill the `bias` of your cnn layers with `0`s.\n",
        "4. Try dropout, batchnorm etc. to improve the results (training speed, restored results etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWTBVqzT_7BU"
      },
      "outputs": [],
      "source": [
        "# implement your network DenoiseNetwork\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "class DenoiseNetwork(nn.Module):\n",
        "    pass\n",
        "\n",
        "# from model import DenoiseNetwork # to skip this part\n",
        "\n",
        "net = DenoiseNetwork().cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ap7h7azIALqX"
      },
      "source": [
        "Here're some basic tests to see if your network can at least run through an example image, this is expected to produce no error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXVKYKrMAZrC"
      },
      "outputs": [],
      "source": [
        "example_batch = training_set[0][0].unsqueeze(0)\n",
        "assert net(example_batch.cuda()).shape == example_batch.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxZS0h3_f2xl"
      },
      "source": [
        "Now we need a quantitative score to indicate how well a network performs. Previously we have defined the psnr function, but it only calculates psnr of an image pair, we need to calculate two scores to see how well the network denoises, the first is the mean psnr score of all noisy images, which indicates how noisy these unprocessed images are, and then assume we have the network ready, we can use the network to predict the noise, and deduct the noise from the noisy images to produce restored images, then we calculate the mean psnr score of these restored images with respect to the original images, and this score indicate how noisy the restored images are. If everything works out fine, we should be able to observe a higher psnr on the restored images.\n",
        "\n",
        "You need to define a `mean_psnr` function that takes a dataset and a network as input and calculate the mean psnr scores of original noisy images across the whole dataset and mean psnr of restored images processed by the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_Ak1jp-gO6d"
      },
      "outputs": [],
      "source": [
        "# implement your mean_psnr function\n",
        "def mean_psnr(testset, net):\n",
        "    return mean_psnr_original, mean_psnr_after\n",
        "\n",
        "# from metrics import mean_psnr # to skip this part\n",
        "# note: to use this mean_psnr function, your network needs to implement a property `device`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJboXubRgoHC"
      },
      "source": [
        "We can calculte the mean psnr on `testing_set`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsHAgP3_gtRt",
        "outputId": "f371f8ae-123d-4242-b087-ee68fae3d005"
      },
      "outputs": [],
      "source": [
        "mean_psnr(testing_set, net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loEC2zEnjFYm"
      },
      "source": [
        "If your code is correct, you should see the mean psnr of original images should be around 28, and the psnr of network processed images is much smaller, which means, a randomly initialzed network adds even more noise, you should see this by displaying."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "-jqQFk-njfDf",
        "outputId": "77fc7b7a-5f32-4d0f-8ae7-4ebd2b9b569c"
      },
      "outputs": [],
      "source": [
        "noisy_image, original_image = testing_set[0]\n",
        "noisy_image = noisy_image.cuda()\n",
        "predicted_noise = net(noisy_image.unsqueeze(0)).squeeze(0)\n",
        "restored_image = noisy_image - predicted_noise\n",
        "\n",
        "fig, axes = plt.subplots(1,3)\n",
        "fig.set_figwidth(15)\n",
        "axes[0].imshow(noisy_image[0].cpu(), cmap='gray')\n",
        "axes[0].axis('off')\n",
        "axes[0].set_title('noisy')\n",
        "axes[1].imshow(original_image[0], cmap='gray')\n",
        "axes[1].axis('off')\n",
        "axes[1].set_title('original')\n",
        "axes[2].imshow(restored_image[0].cpu().detach(), cmap='gray')\n",
        "axes[2].axis('off')\n",
        "axes[2].set_title('restored')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U6d1Vkze80g"
      },
      "source": [
        "## 4. Training\n",
        "Now that we got everything ready, we should start training, in the next section, you need to implement the training process, that includes defining criteria, setting up optimizer, going through several epochs to train the network, during the training, you should also analyze the psnr scores to see how it goes in terms of quantified performance.\n",
        "\n",
        "Checklist:\n",
        "1. define dataloader, recommend batch size starting from 32\n",
        "2. criteria\n",
        "3. optimizer\n",
        "4. (optional) consider using functions in torch.optim.lr_scheduler to adjust your learning rate, because smaller learning rate might work better in the later period of training, similar to fine adjustment. Reference: https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
        "5. during each iteration, you need to 1. get the noisy image and the original image 2. calculate predicted noise from network, use MSE to calculate the distance between predicted noise and true noise 3. reset gradients to zero 3. use the distance as loss to backward the network to get gradients 4. perform learning with the gradients using optimizer\n",
        "6. From time to time (e.g. each epoch), calculate PSNR on testing_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c71ROEBTiQs1",
        "outputId": "101500d4-f6da-4910-b174-98d945a9c184"
      },
      "outputs": [],
      "source": [
        "# implement your training steps\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "\n",
        "# fill your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NR87pE8fazs"
      },
      "source": [
        "Now that your net is ready, we can re do the demonstration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "dTMhrzj5jGD4",
        "outputId": "9e8d4f65-49eb-47f3-f71f-7c71962f0104"
      },
      "outputs": [],
      "source": [
        "noisy_image, original_image = testing_set[0]\n",
        "noisy_image = noisy_image.cuda()\n",
        "predicted_noise = net(noisy_image.unsqueeze(0)).squeeze(0)\n",
        "restored_image = noisy_image - predicted_noise\n",
        "\n",
        "fig, axes = plt.subplots(1,3)\n",
        "fig.set_figwidth(15)\n",
        "axes[0].imshow(noisy_image[0].cpu(), cmap='gray')\n",
        "axes[0].axis('off')\n",
        "axes[0].set_title('noisy')\n",
        "axes[1].imshow(original_image[0], cmap='gray')\n",
        "axes[1].axis('off')\n",
        "axes[1].set_title('original')\n",
        "axes[2].imshow(restored_image[0].cpu().detach(), cmap='gray')\n",
        "axes[2].axis('off')\n",
        "axes[2].set_title('restored')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-PONrrroWEy"
      },
      "source": [
        "The network I trained here is a simple 3-layer low number of channel cnn network, and you can see it's already starting to work. Now try adjust some parameters/network structure to make it work even better. Write down your analysis to make a pdf report.\n",
        "\n",
        "You need to submit two files, this ipynb file and a pdf report with your analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCteUONkoyoH"
      },
      "source": [
        "#Marking Scheme:\n",
        "\n",
        "\n",
        "*   Code implementation: 60%\n",
        "\n",
        "\n",
        "> * Dataset 10%\n",
        "> * Metrics 5%\n",
        "> * Network 5% (only 5% because network overlaps with results, you need to adjust the network to improve the results anyway)\n",
        "> * Training code 10%\n",
        "> * reasonably good results 30% (with 10% bonus if the results are exceptional)\n",
        "\n",
        "\n",
        "*   PDF report: 40%\n",
        "\n",
        "> * Basic results demonstration (network introduction, denoising results showcase) 15%\n",
        "> * Analysis and improvements 25% (You're supposed to clarify how do you make the network work, e.g. if you encounter some issues, what do you do to address them)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
